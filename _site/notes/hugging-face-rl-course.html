<!DOCTYPE html><html lang="en" ><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" href="/assets/images/resources/favicon.png" type="image/png"><link rel="stylesheet" href="/fugg2.css"> <script src="https://cdn.jsdelivr.net/npm/gsap@3.12.5/dist/gsap.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/gsap@3.12.5/dist/ScrollTrigger.min.js"></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script></head><body> <script> if (localStorage.theme === 'dark' || (!('theme' in localStorage) && window.matchMedia('(prefers-color-scheme: dark)').matches)) { document.querySelector('body').classList.add('theme-dark') } </script><div id="menu-overlay"><nav class="stickysidebar"><ul class="stickysidebar-list"><li class="stickysidebar-list-item"><a href="/">[&nbsp;&nbsp;] Casa/Home</a></li><li class="stickysidebar-list-item"><a href="/newhere.html">[&nbsp;&nbsp;] If you're new here</a></li><li class="stickysidebar-list-item"><a href="/about.html">[&nbsp;&nbsp;] About</a></li><li class="stickysidebar-list-item"><a href="/building.html">[&nbsp;&nbsp;] Building</a></li><li class="stickysidebar-list-item"><a href="/writing.html">[&nbsp;&nbsp;] Writing</a></li><li class="stickysidebar-list-item"><a href="/notes.html">[&nbsp;&nbsp;] Notes</a></li><li class="stickysidebar-list-item"><a href="/misc.html">[&nbsp;&nbsp;] Misc</a></li><li class="stickysidebar-list-item"><a href="/contact.html">[&nbsp;&nbsp;] Contact</a></li><li class="stickysidebar-list-item"><a href="/cv.html">[&nbsp;&nbsp;] CV</a></li><li class="stickysidebar-list-item"><a href="https://github.com/thomaspradae">[&nbsp;&nbsp;] GitHub</a></li><li class="stickysidebar-list-item"><a href="https://twitter.com/thomas__prada">[&nbsp;&nbsp;] Twitter</a></li><li class="stickysidebar-list-item"><a href="/rss.html">[&nbsp;&nbsp;] RSS</a></li></ul></nav><div class="menu-content"></div></div><button id="menu-button" class="menu-button" onclick="toggleMenu()">[ MENU ]</button><main class="content"><div class="page-content"> <!DOCTYPE html><html lang="en"><head><title>deep reinforcement learning course notes (hugging face) / thomasprada</title><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script></head><body><div class="post-header"><div class="post-meta-container"><div class="post-meta-container-left-side"><section class="breadcrumbs"> <a href="/notes.html">Notes</a> > <a href="/notes/hugging-face-rl-course">Deep Reinforcement Learning Course Notes (Hugging Face)</a></section></div><div class="vertical-line"></div><div class="post-meta-container-right-side"><div class="meta"><div class="post-meta-date"><p class="title-post-meta-p">Published on</p><time class="date-post" datetime="2024-05-30T00:00:00-05:00">May 30, 2024</time></div><p class="title-post-meta-p">Tags</p><div class="tags-holder"> <a class="internal-link" href="/tag/reinforcement-learning">reinforcement learning</a> / <a class="internal-link" href="/tag/deep-reinforcement-learning">deep reinforcement learning</a> / <a class="internal-link" href="/tag/ml">ml</a></div></div></div></div><div class="line contrast"></div></div><section class="post"><h1 class="page-title">Deep Reinforcement Learning Course Notes (Hugging Face)</h1><h1 id="its-literally-all-for-the-dawgs-lfg">IT’S LITERALLY ALL FOR THE DAWGS LFG</h1><h2 id="000---the-big-picture-and-rl-learning-framework">(0.0.0) - THE BIG PICTURE AND RL LEARNING FRAMEWORK</h2><p>The big idea behind reinforcement learning is that an agent will be able to learn from an environment by <em>interacting with it</em>, which will lead to rewards (which can be either negative (punishment) or positive) which serve as <em>feedback</em> after performing actions.</p><p>The example given in the course is the following: imagine you have a little brother, and you set him in front of a video game he’s never seen or played. He’ll probably start off by figuring his way around the controls. Maybe he somehow manages to collect some prize like a coin, he then realizes that doing so will increase his score. Now say he manages to run into an enemy, in touching the enemy he learns that doing so reduces his score. Through interaction, he learns about the environment.</p><h3 id="001---rl-process">(0.0.1) - RL PROCESS</h3><p>The process described above can be modeled as follows: <img src="../assets/images/posts/RL_process.jpg" alt="RL_process" /> <em>Source: Hugging Face Deep RL Course - Unit 1 - “RL Framework”</em></p><p>We encounter a loop: An agent interacts with a given state (say, the world a specific moment in time / with a specific organization (set of information)), which is related to (or involves / or comes with) a reward<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>. The agent then takes a decision based on these, thereby changing the environment through it’s action, resulting in a new state and a new reward. This in turn ends up being a loop involving an agent, states (\( S_t \), \( S_{t+1} \), \( \dots \), \( S_n \)), actions (\( A_t \), \( A_{t+1} \), \( \dots \), \( A_n \)) and rewards (\( R_t \), \( R_{t+1} \), \( \dots \), \( R_n \)).</p><p>Reinforcement learning is based on the <em>reward hypothesis</em>:</p><blockquote><p>“All of what we mean by goals and purposes can be well thought of as maximization of the expected value of the cumulative sum of a received scalar signal (reward)”</p><p><em>(Sutton, 2004; Sutton &amp; Barto, 2018; Littman, 2017).</em></p></blockquote><p>In other words, we can express the agent’s goal as a maximization problem, the maximization of its reward. This entails that we’d have to make sure our environment is set up / expressed in such a way that it’s able to capture this dynamic. For instance, consider we’re trying to teach our agent how to score a goal<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup>. To do so, we’d have to make sure our agent has access to a set of actions that can allow it to satisfy such a goal (say, moving in a given direction, kicking, etc.), and that it receives information (a new state and a reward) based on the action it takes. Furthermore, this information is specified, such that, if the agent attempts to choose reward maximizing actions, it will lead closer to the completion of the goal (hopefully up to the full completion of the goal). Enough with the abstractions, let’s get back to our football example. In this case, since we want our agent to score a goal, we might reward it when the ball is closer to goal and punish it when its further away. In this sense, as our agent is trying to maximize the reward, it might try strategies (such as kicking the ball when its facing the goal) that result in the ball being as close to goal as possible (until it’s ultimately in goal).</p><h3 id="002---markov-property-markov-decision-process">(0.0.2) - MARKOV PROPERTY, MARKOV DECISION PROCESS</h3><p>This RL process we’ve just discussed is called a <a href="https://en.wikipedia.org/wiki/Markov_decision_process">Markov Decision Process (MDP)</a><sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">3</a></sup>. A MDP is a discrete time stochastic control process. Let’s unpack that:</p><ul><li><p><em>Discrete-time</em>: instead of thinking of time as continuous (say, the way in which an hour can be divided into minutes, and seconds, and each second can be divided into even smaller divisions, meaning, that between any two points in time there are infinitely more points in time), think of there being ‘separate points in time’, for example \( t = 1, 2, 3, \dots n \)where each value of t is a point in time. Time “jumps” from one to the next.</p></li><li><p><em>Stochastic</em>: stochasticity (from the Greek (stokhos) which means to aim or guess) is commonly used interchangeably with ‘randomness’. The wiki page for stochasticity defines it as the ‘property of being well-described by a random probability distribution’. A probability distribution is a mathematical function that tells us the probability of occurrence of different outcomes of a given phenomenon / experiment / process.<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote" rel="footnote">4</a></sup> For example, imagine a fair dice</p></li><li></li><li></li><li>interchanged with ‘randomness’. The wiki page for stochasticity says that it is ‘the property of being well-described by a random probability distribution’. A probability distribution is simply a mathematical function that tells us the probability of occurrence of different outcomes of a given phenomena / experiment. Now, just to avoid confusion, in case it’s needed,</li><li></li><li></li><li>A <em>random</em> probability distribution</li><li><em>Control</em>:</li><li></li><li>in a way that ultimately, there are no ‘jumps’ so to speak between units of time)</li></ul><p>\[ S_{t+1} = f(S_t, A_t) \]</p><p>Here is an inline equation \( e^{i\pi} + 1 = 0 \)</p><p>Here is an inline equation \( e^{i\pi} + 1 = 0 \)</p><p>Here is an dosplay equation \[ e^{i\pi} + 1 = 0 \ \]</p><p>This is some shit that needs no converting you see like this $100 USD or maybe something like</p><p>$100 and $100</p><p>And now here is some latex:</p>\[e^{something} + 1\] \[100 \cdot 100 1\]<p>And now some inline $t_0$</p><p><a href="Pasted image 20240530180557.png">Hi</a> There can be quite a bit of terminology to unpack</p><p>I’l try and delve into this deeper myself</p><p>The RL process yes</p><p><a href="obsidian://open?vault=Origin%20OS&amp;file=Screenshot%202024-05-30%20180322.png">stochastic</a></p><p><img src="../assets/images/posts/Screenshot%202024-05-30%20180322.png" alt="Screenshot 2024-05-30 180322" /></p><div class="footnotes" role="doc-endnotes"><ol><li id="fn:1" role="doc-endnote"><p>In the case where it’s the first interaction, the state \( S_0 \) would also have a reward, \( R_0 \), which tends to be 0. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p></li><li id="fn:2" role="doc-endnote"><p><a href="https://www.youtube.com/watch?v=6TnKvlQ2h7s&amp;ab_channel=Super6">Football</a>, or Soccer, for those from the states. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p></li><li id="fn:3" role="doc-endnote"><p>The course says it delves deeper into this later on, so we’ll see, however, I wish to do so myself as well, so for now we’ll have just a quick overview, and later on, depending on what the course covers, we’ll see what needs to be specified further. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p></li><li id="fn:4" role="doc-endnote"><p>I promise to dive deeper into this elsewhere, so there should probably be a link here, if there isn’t, maybe I forgot to link it so it might be somewhere in <code>notes</code> <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p></li></ol></div></section></body></div></main><footer><div class="footer-line"></div><div class="footer-info"><div class="info-item"> <img src="/assets/images/resources/lightestemptyball.svg" alt="Icon" class="info-icon_1"><p>4°36'17.8"N 74°03'16.9"W</p></div><div class="info-item"> <img src="/assets/images/resources/lightestball.svg" alt="Icon" class="info-icon_2"><p id="bogota-weather">Bogotá --°C, --:--</p></div></div><div class="footer-bottom"> <img src="/assets/images/resources/POSLIGHTGREY.png" alt="Pattern" class="footer-image"><div class="footer-text"> <span class="year">mmxxiv</span> <span class="name">ThomasPrada.</span></div></div></footer><button id="theme-toggle">Dark Mode</button> <script src="https://cdn.jsdelivr.net/npm/gsap@3.12.5/dist/gsap.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/gsap@3.12.5/dist/ScrollTrigger.min.js"></script> <script> gsap.registerPlugin(ScrollTrigger); if (window.innerWidth > 600) { console.log("Screen width is greater than 600px, animation active"); gsap.to(".stickysidebar", { scrollTrigger: { trigger: ".footer-line", start: "top 100%", end: "bottom 10%", scrub: 1, }, y: -500, }); } else { console.log("Screen width is less than 600px, animation inactive"); } </script> <script> var darkModeToggle = document.querySelector("#theme-toggle"); const lightThemeImages = { "icon1": "/assets/images/resources/lightestemptyball.svg", "icon2": "/assets/images/resources/lightestball.svg", "footericon": "/assets/images/resources/POSLIGHTGREY.png", }; const darkThemeImages = { "icon1": "/assets/images/resources/darkestemptyball.svg", "icon2": "/assets/images/resources/darkestball.svg", "footericon": "/assets/images/resources/POSDARKGREY2.png", }; function toggleTheme() { document.body.classList.toggle("theme-dark"); updateThemeState(); updateButtonLabel(); const isDarkMode = document.body.classList.contains("theme-dark"); const themeImages = isDarkMode ? darkThemeImages : lightThemeImages; document.querySelector('.info-icon_1').src = themeImages.icon1; document.querySelector('.info-icon_2').src = themeImages.icon2; document.querySelector('.footer-image').src = themeImages.footericon; console.log("Theme toggled:", document.body.classList.contains("theme-dark") ? "Dark Mode" : "Light Mode"); } function updateThemeState() { let isDarkMode = document.body.classList.contains("theme-dark"); let theme = isDarkMode ? "dark" : "light"; localStorage.setItem("theme", theme); darkModeToggle.setAttribute("aria-checked", isDarkMode.toString()); console.log("Theme updated in localStorage to:", theme); } function updateButtonLabel() { darkModeToggle.textContent = `${document.body.classList.contains("theme-dark") ? 'Light' : 'Dark'} Mode`; } function initializeTheme() { let isDarkMode = document.body.classList.contains("theme-dark"); darkModeToggle.setAttribute("aria-checked", isDarkMode.toString()); updateButtonLabel(); const themeImages = isDarkMode ? darkThemeImages : lightThemeImages; document.querySelector('.info-icon_1').src = themeImages.icon1; document.querySelector('.info-icon_2').src = themeImages.icon2; document.querySelector('.footer-image').src = themeImages.footericon; console.log("Theme initialized:", isDarkMode ? "Dark Mode" : "Light Mode"); } darkModeToggle.addEventListener("click", toggleTheme); document.addEventListener('DOMContentLoaded', initializeTheme); window.addEventListener('keydown', function(e) { if (document.activeElement.tagName === 'INPUT' || document.activeElement.tagName === 'TEXTAREA') { return; } if (e.key === 'd' || e.key === 'D') { toggleTheme(); } }); initializeTheme(); </script> <script src="/mobilemenu.js"></script> <script src="/weather.js"></script></body></html>
